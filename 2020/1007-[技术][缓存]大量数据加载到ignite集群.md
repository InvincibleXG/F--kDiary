# 大量数据加载到Ignite集群的实践

首先呢，要知道 [ignite](https://apacheignite.readme.io/docs) 是啥，一个开源分布式存储和计算平台。

刚开始我以为其主要功能就是将数据存在内存中，其实对于集群里的每个正常节点，最基本的，都具备`计算`的功能，而只有加入`baseline`的节点，才有资格进行数据存储。



当然回归标题，要把大量数据加载到 ignite集群，其实要注意几个 key point :

1. 数据的量级和来源
2. 关系型[或者其他类型的]数据到Entry型数据的结构转换
3. 如何利用计算节点分布式加载
4. 利用亲和性缓存机制并发整合不同key的数据
5. 是否还有其他优化途径



实际的关键流程设计呢，其实也就是：

1. 找到所有可用的物理计算节点，把执行时需要的jar包放好
2. 在各个节点上分别初始化数据源连接
3. 事先准备好任务划分算法或者是写死的任务配置，比如某个节点加载某一段数据尽量产生交集和少量冗余
4. 对于数据映射，动态提供RowMapper转换
5. 业务上的数据合并操作，能不用EntryProcess和事务就尽量不要使用，以提升性能
6. 数据校验，确定任务是否完成和是否需要重新执行
7. 在各个节点清掉`临时Cache`和回收资源



